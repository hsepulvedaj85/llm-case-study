
# ğŸ§  Retrieval-Augmented Generation (RAG) Pipeline

This project implements a **RAG (Retrieval-Augmented Generation)** system that:

- Processes and chunks PDF documents
- Embeds and stores those chunks in a **Milvus** vector database
- Answers user questions using **LLM: LLaMA 3.2-1B** (by using [Ollama](https://ollama.com))
- Uses **Snowflake Arctic Embed-s** for embedding
- Provides a FastAPI interface and evaluation pipeline

---
## ğŸ“¦ Environment Setup

To run this project, you will need to download software like Ollama and docker; and configure your enviroment to run properly.

### âœ… Requirements

- Python: `3.8+`
- OS: Linux/macOS/Windows
- Docker Desktop for Windows
- Follow the installation recommendations below:
  - **Docker Linux**: https://milvus.io/docs/install_standalone-docker.md
  - **Docker Compose (Linux)**: https://milvus.io/docs/install_standalone-docker-compose.md
  - **Docker Desktop (Windows)**: https://milvus.io/docs/install_standalone-windows.md
- Download Ollama: https://ollama.com/download

### ğŸ“¥ Docker Desktop (Windows):
- _Install Docker Desktop_: https://docs.docker.com/desktop/setup/install/windows-install/
- _Install Windows Subsystem for Linux 2 (WSL 2)_: https://learn.microsoft.com/en-us/windows/wsl/install#install-wsl-command
- _Install Python 3.8+_.

### 1. On Windows (Command Prompt):
  DOS
  set PYTHONUTF8=1

### 2. On Windows (PowerShell):
  PowerShell
  $env:PYTHONUTF8=1

### 3. On Linux/macOS:
  Bash
  export PYTHONUTF8=1
---
## ğŸ§° Project Installation

### 1. Clone the project

```bash
  #  Clone the project
  git clone https://github.com/hsepulvedaj85/llm-case-study.git
  cd llm-case-study
```
### 2. Install virtual enviroment
```bash
  pip install virtualenv
```
### 3. Create virtual enviroment
```bash
  cd ll-case-study
  python3.12 -m venv venv
  source venv/bin/activate
```
### On Windows use

```bash
  cd ll-case-study
  virtualenv venv
  venv\Scripts\activate
```
## ğŸ”§ Dependency Installation

All dependencies are listed in requirements.txt.

```bash
  pip install -r requirements.txt
```
### ğŸ—ƒï¸ Vector Store (Milvus) Setup: https://milvus.io/docs/quickstart.md
#### âœ… Requirements: https://milvus.io/docs/prerequisite-docker.md

With the docker-compose.yml file in the root of the project first run dockerdesktop and then make sure you have the virtual environment `(venv)`  active to run:

```bash
  docker-compose up -d
```
### ğŸš€ Run the RAG Pipeline
In CMD or PowerShell (after activating venv):

```bash
  python pipeline.py
```

## ğŸ” API Reference
To activate in virtual enviroment after running first pipeline "pipeline.py"

```bash
  uvicorn app:app --reload --port 8000
```

#### Get an answer

```http
  POST /query
```

| Parameter | Type     | Description                |
| :-------- | :------- | :------------------------- |
| `Content-Type` | `application/json` | **Required**. question |

#### Example:

```json
  {
  "question": "What significant technological advancement is Veridia known for in agriculture?"
  }
```

#### ğŸ¯ Retrieves and approximates an answer in JSON Format
```json
  {
  "answer": "Veridia is known for innovations in hydroharmonic farming technology that have revolutionized their yield."
  }
```

## ğŸ§ª Running Tests

To run tests, run the following command

### ğŸ“„ Send POST request to:
```json
  $> POST http://localhost:8000/query
  {
    "question": "What is the official language of Veridia?"
  }
```

### Test via curl:
```bash
  curl -X POST http://localhost:8000/query -H "Content-Type: application/json" -d '{"question": "What is the capital of Veridia?"}'
```

## ğŸ“Š Evaluation Pipeline

### ğŸ“ Files Needed:
```
data/questions.txt (One question per line)

data/answers.txt (One answer per line, same order)
```

### ğŸ“ˆ Run Evaluation:
```bash
  python pipe_eval.py
```

This script will:
- Generate predictions using the same pipeline

- Embed both expected and generated answers

- Compute cosine similarity

- Save results to evaluation_report.txt
## ğŸ“ Project Structure

The project is organized as follows:

```php
  llm_case_study/
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ dr_voss_diary.pdf      # The document to process
    â”‚   â”œâ”€â”€ questions.txt          # Questions to answer
    â”‚   â”œâ”€â”€ answers.txt            # Answers to the questions, for evaluation/testing purposes
    â”‚   â””â”€â”€ evaluation_report.txt  # Questions, answers and predicted answers with COSINE similarity 
    â”œâ”€â”€ scripts/
    â”‚   â”œâ”€â”€ prepare_data.py        # Load and preprocess PDF file
    â”‚   â””â”€â”€ eval.py                # Evaluation pipeline
    â”œâ”€â”€ src/                    
    â”‚   â”œâ”€â”€ chunker.py             # PDF Load, prepare and split into chunks
    |   â”œâ”€â”€ embedder.py            # Embedding logic 
    |   â”œâ”€â”€ final_answer.py        # Generates answer to a query based
    |   â”œâ”€â”€ milvus_client.py       # Milvus setup & ingestion
    |   â””â”€â”€ search.py              # Searches Milvus collection based on a given query embedding.
    â”œâ”€â”€ test/
    |   â””â”€â”€ search_reranker.py     # test with re-rankink Cross Encoder 'ms-marco-TinyBERT-L-2-v2'
    â”œâ”€â”€ app.py                     # FastAPI server implementation
    â”œâ”€â”€ pipeline.py                # End-to-end runner Document processing pipeline to Milvus.
    â”œâ”€â”€ README.md                  # Project documentation
    â”œâ”€â”€ requirements.txt           # List of needed librarys
    â””â”€â”€ docker-compose.yml         # file to run Milvus.  
```