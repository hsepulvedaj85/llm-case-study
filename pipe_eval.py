from src.embedder import Embedder
from src.search import search_embedding
#from src.search_reranker import search_embedding
from src.final_answer import generate_answer
from sklearn.metrics.pairwise import cosine_similarity
from scripts.eval import eval_file
import numpy as np

def run_pipeline(questions_file_path,answers_file_path):
    """
    Executes an end-to-end evaluation pipeline for a RAG (Retrieval-Augmented Generation) system.

    This function orchestrates the following steps:
    1. **Loads Questions and Expected Answers:** Reads a list of questions and their
       corresponding ground-truth answers from specified text files.
    2. **Runs Queries through RAG System:** For each question, it performs the
       RAG process:
        a. **Embeds the Query:** Converts the question into a numerical vector embedding.
        b. **Retrieves Context:** Searches a Milvus vector database to find relevant
           document chunks based on the query embedding.
        c. **Generates Answer:** Uses a Large Language Model (LLM) to generate an
           answer based on the original question and the retrieved context.
    3. **Evaluates Performance:** Compares the generated (predicted) answers with the
       expected answers using semantic similarity (cosine similarity) and
       generates a detailed evaluation report.

    Args:
        questions_file_path (str): The file path to the text file containing questions,
                                   one question per line.
        answers_file_path (str): The file path to the text file containing the expected
                                 answers, one answer per line, corresponding to the questions.

    Example:
        >>> run_pipeline("./data/questions.txt", "./data/answers.txt")
        # This will load questions, run them through the RAG system, and generate an evaluation report.
    """
    # Paths to files
    questions_file = questions_file_path
    answers_file = answers_file_path

    print(f"Load questions and expected answers\n")
    #   Load questions and expected answers
    with open(questions_file, "r", encoding="utf-8") as f:
        questions = [line.strip() for line in f if line.strip()]

    with open(answers_file, "r", encoding="utf-8") as f:
        expected_answers = [line.strip() for line in f if line.strip()]

    def run_query(query: str):
        """
        Internal helper function to process a single query through the RAG pipeline.

        Args:
            query (str): The question string to be processed.

        Returns:
            str: The final answer generated by the RAG system.
        """
        #embedder
        #print("Embeder")
        embedder = Embedder()
        embedding = embedder.embed_texts(query)
        #print("Search")
        context = search_embedding(embedding)
        #context = search_embedding(embedding, query)
        #print("Ollama")
        final_answer = generate_answer(query, context)
        #print(f"Finaliza run query")
        return final_answer


    # Embed your query
    predicted_answers = [run_query(question) for question in questions ]

    eval_file(questions, expected_answers, predicted_answers)

if __name__ == "__main__":
    run_pipeline("./data/questions.txt","./data/answers.txt")